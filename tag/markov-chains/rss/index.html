<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ns0="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Markov Chains - I-Process</title><description>Thoughts and Ideas on Physics, Astronomy and Computer Science.</description><link>http://127.0.0.1:2368/</link><generator>Ghost 0.5</generator><lastBuildDate>Fri, 30 Jan 2015 19:24:18 GMT</lastBuildDate><ns0:link href="http://127.0.0.1:2368/tag/markov-chains/rss/" rel="self" type="application/rss+xml" /><ttl>60</ttl><item><title>The Making of a Markov Chain</title><description><![CDATA[<p>Before getting into how to make Markov Chains, lets quickly get a refresh on what a Markov Chain is. A Markov Chain is a set of states and state transition which are selected based on an assigned probability of occurring. The goal of a Markov chain is to model complex ...</p>]]></description><link>http://127.0.0.1:2368/the-making-of-a-markov-chain/</link><guid isPermaLink="false">efb6c223-d7bb-42dc-8536-e078593a8b70</guid><category>Statistics</category><category>Markov Chains</category><category>Python</category><dc:creator>Luke Siemens</dc:creator><pubDate>Sat, 19 Jul 2014 19:20:43 GMT</pubDate></item><item><title>An Introduction to Markov Chains</title><description><![CDATA[<p>Markov chains are a statistical tool invented by Andrey Markov to model dependent statistical phenomenon. A Markov Chain is made from two components a discrete set of states and a set of stochastic state transitions. The idea is that if there are two states <strong>A</strong> and <strong>B</strong> and the state ...</p>]]></description><link>http://127.0.0.1:2368/an-introduction-to-markov-chains/</link><guid isPermaLink="false">786ebf52-0367-453f-b660-be35f5b11c4c</guid><category>Statistics</category><category>Markov Chains</category><dc:creator>Luke Siemens</dc:creator><pubDate>Sun, 08 Jun 2014 00:28:00 GMT</pubDate></item></channel></rss>