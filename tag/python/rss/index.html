<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ns0="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Python - I-Process</title><description>Thoughts and Ideas on Physics, Astronomy and Computer Science.</description><link>http://127.0.0.1:2368/</link><generator>Ghost 0.5</generator><lastBuildDate>Sun, 08 Mar 2015 01:32:41 GMT</lastBuildDate><ns0:link href="http://127.0.0.1:2368/tag/python/rss/" rel="self" type="application/rss+xml" /><ttl>60</ttl><item><title>PsiPy: Schr&#246;dinger's Equation (part 1)</title><description><![CDATA[<p>This past fall I was taking my second quantum mechanics class. In that class we learnt how to deal with discreet quantum system using linear algebra and how to extend that notation to solve continuous systems. Midway though the semester I attempted to write a simple program to solve the ...</p>]]></description><link>http://127.0.0.1:2368/psipy-schrodingers-equation-part1/</link><guid isPermaLink="false">9583b4c4-c501-49b5-8754-d00af98be05a</guid><category>Python</category><category>Quantum Mechanics</category><category>Schr&#246;dinger's Equation</category><dc:creator>Luke Siemens</dc:creator><pubDate>Sat, 07 Mar 2015 20:00:00 GMT</pubDate></item><item><title>Memory and Markov</title><description><![CDATA[<p>In a previous post I discussed how to generate a Markov Chain with a basic algorithm, but using that algorithm memory usage was a limiting factor. Now we will attempt to find a solution to the memory usage of the algorithm. If you are unfamiliar with how to generate a ...</p>]]></description><link>http://127.0.0.1:2368/memory-and-markov/</link><guid isPermaLink="false">dec74fc3-ec72-4593-a58b-39e086102863</guid><category>Statistics</category><category>Markov Chains</category><category>Python</category><dc:creator>Luke Siemens</dc:creator><pubDate>Wed, 04 Feb 2015 19:30:44 GMT</pubDate></item><item><title>The Making of a Markov Chain</title><description><![CDATA[<p>Before getting into how to make Markov Chains, lets quickly get a refresh on what a Markov Chain is. A Markov Chain is a set of states and state transition which are selected based on an assigned probability of occurring. The goal of a Markov chain is to model complex ...</p>]]></description><link>http://127.0.0.1:2368/the-making-of-a-markov-chain/</link><guid isPermaLink="false">efb6c223-d7bb-42dc-8536-e078593a8b70</guid><category>Statistics</category><category>Markov Chains</category><category>Python</category><dc:creator>Luke Siemens</dc:creator><pubDate>Sat, 19 Jul 2014 19:20:43 GMT</pubDate></item></channel></rss>