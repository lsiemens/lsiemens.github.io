---
layout: post
title: "Fractional Calculus and Taylor Series"
tags: [Math, Taylor-series, Calculus, Fractional-Calculus]
math: true
---

fractional callculus is the attempt to solve equations of the form $\sqrt{\frac{d}{dx}}f(x)$ that is what operator when applied twice is equal the the derivat and other problems in the save vane. in general fractional differentiation is generalized from that idea to raising the derivative operator to an arbitrary exponent and like wise for fractional integration. the idea that such an obect might exist is motivatied by alalogy to how repeated multiplication can be extended to eponentiation. and this leads to the posibility that just like exponentiaon is a much broader than just repeated multiplication the posibility that fractional calculus might lead to intresting implecations far beyond repeated differentiation. if you consider the nth order repeated integral of a constant over some bounds the result can be interprted of the size of a "square" in n dimensional space, ie the length of an interval, area of a square and volume of a cube and so on. applying the same interpritaion to fractional integration leads to the obserdity of considering the size of a square in a space does not have an integer number of dimensions. inspite of this fractional calculus has been put to practical use in solving problems in electrochemistry, anomolus diffusion, PID controll theory and even clasical mechanics. for example Niels Able showed in 1823 that the tautochrone problem can be expressed interms of fractional calculus.


there is a problem there is not just one fractional derivative, infact multiple fractional derivative and integral operators have been found. all of which are fractional generalizations of differentiation and integration and they are ingeneral incompatible with each other. thatis applying two differnt fractional derivativs to the same function ingeneral produces differnt results. So fractional calculus is not uniquely defined. additioaly continuing the analolgy betwean fractional calculus and exponentian you might expect fractional derivative and integrals to follow the index rule $\frac{d^\alpha}{dx^\alpha}\frac{d^\beta}{dx^\beta} = \frac{d^{\alpha + \beta}}{dx^{\alpha + \beta}}$ for any real numbers $\alpha$ and $\beta$. but this is not the case, for example consider the Riemann Luivile fractional integral $I_a^\alpha f(x) = \frac{1}{\Gamma(\alpha)} \int_a^x (x - t)^{\alpha - 1} f(t)dt$ with exponent $\alpha=\frac{1}{2}$ somtimes caled the semi-integral, the derivative of the semi-integral of a constant is $\frac{d}{dx} (I_0^{1/2} b) = \frac{b}{\sqrt{\pi x}}$ however the semi-integral of the derivative of a constant is $I_0^{1/2} (\frac{d}{dx} b) = 0$. so the Riemann Luivile fractional integeral does not satisfy the index rule, more generaly fractional derivaties and integrals do not satisfy the index rule. these two properies in contrast to the simple generalizing consept of fractional calculus just does not feel right, like an itch i can not scratch.that being said mathamatical objects often do not behave like you expect them to initaly, and intuition about new things in math is often wrong. that bing said somtimes we are just not asking the right questions so math built off that has may have quirks and hangups due to somthing that should have been added in or left out. so with that in mind if we know where these two properties come from, what causes fractional calculus to behave like it does, that might enable us to ask better questions or atleast understan what was missing in our innitial intuition of how it should behave.


before jumping in, I should be clear about wheat i mean by fractional differentiation in the first place. for the perposus here by fractional differentiation, i mean a operator that acts on functions and has a variable call the index (or exponent) such that for positive values of the index it reproduce repeaded differentiation. and that like the derivative and integral operators is a linear operator.

### understanding index rule violation ###
fractional differentiant and integration failes to satisfy the index property. Why is this the case? partialy it is the result of differential calculus itself. the index would imply that $\frac{d^{-1}}{dx^{-1}}$ must be the inverse of the derivative since, $\frac{d^{-1}}{dx^{-1}} \frac{d}{dx} = \frac{d}{dx} \frac{d^{-1}}{dx^{-1}} = \frac{d^0}{dx^0}$ where $\frac{d^0}{dx^0}$ is the identity operator. however while the indegral is nearly the invers of the derivative (it is a right inverse of the derivative), the derivative is not invertable in general. so every fractional derivative which by definition must reprioduce differentiation for integer values, thus can not satisfy the index rule since $\frac{d^{-1}}{dx^{-1}}$ does not exist. so at least the index rule cannot apply for all real numbers, but at most some subset.


however this leads to an obvious workaround, what if we restriced the domain of functions that we consider for calculsu. such that differentiation and intergration was invertable. if we considered functions of the form $f(x) = P(x)e^x$ where $P(x)$ is a finite order polynomial, lets call the set of all functions of that form $\mathbb{S}$. so consider the collection of $(\mathbb{S}, \int_{-\infty}^x f(t)dt, \frac{d}{dx})$, the only antiderivative of a function in $\mathbb{S}$ which is also in the same set is given by the integral listed, and that integral and derivate when restricted to functions in $\mathbb{S}$ are true inverses of each other. so the operator 
\begin{equation\*}
J^n f(x)=\begin{cases}\frac{1}{(n -1)!}\int_{-\infty}^x (x - t)^{n - 1}f(t)dt, & \text{for $n \geq 1$} \newline
f(x), & \text{for $n = 0$} \newline
\frac{d^{|n|}}{dx^{|n|}} f(x), & \text{for $n \leq -1$}\end{cases}
\end{equation\*}
that reproduces repeated integration and differentiation, compatible with the integral listed above. then this operator when acting on functions in $\mathbb{S}$ forms a group and statisfies the index rule $J^nJ^m f(x) = J^{n+m} f(x)$ for all $n, m \in \mathbb{Z}$. a fractional version of this operator does not imply any violation of the index rule, since it is invertable. so then it is posible but not garentied that a fractional version of this operator could satisfy the index rule.

### Invertability of the derivative: Taylor series ###
restricting the domain of functions is one way to make integration invertable. alternativly we can consider why differentiation is not invertable in the first place. this can be seen from the fundemental theorem of calculus, but a more direct way is to see the action of the derivative on a taylor series. given that complex analytic function are uniquely defined by their taylor series, a complex analytic function $f(z)$ can be represented as the sequence of complex numbers $(a_0, a_1, a_2, ..., a_k, ...)$ such that $f(z) = \Sigma_{k=0}^\infty \frac{a_k}{k!}z^k$. Now let us consider the derivative of $f(z)$, the function $f'(z) = \frac{d}{dz} f(z) = \Sigma_{k=0}^\infty \frac{a_{k + 1}}{k!}z^k$, which has the representation $(a_1, a_2, a_3, ..., a_{k + 1}, ...)$. So interms of the sequence representation of analytic functions, the derivative is an operator which removes the first element from the sequence. So then the nth derivative of a sequence remove the first $n$ elements resulting in the representation $(a_n, a_{n + 1}, a_{n + 2}, ..., a_{n + k}, ...)$. Looking at differentiation in this way it is clear that differentiation is not invertible. it can not be inverted because taking the derivatie of a function litearly removes the information that was contained in the first element of the sequence, and there does not exist an operation which can, in general, reconstruct what the original first element was. Note that in the case of functions in the set $\mathbb{S}$, they are defined such that their taylor seriese at the point $z_0$ under the limit as $z_0 \to -\infty$ has the series representation $(0, 0, 0, ..., 0, ...)$. so no information is actualy lost when taking the derivative of functions in $\mathbb{S}$, since it can be reconstructed trivialy.


so with this in mind if we wanted to make calculus invertable with out gratly restricting the domain of functions, we could instead define a generalized function based on the series representation of analytice functions and define the derivative such that every time we differentiate one of these functions the leading term of the seriese representition gets packadged along with the new function. then the an inverse operator to the derivative nessisaraly exists. the inverse would unpack the most reasent peace of extra information and put it as the first entry of the series representation followed by the existing ones, this corisponds to precicly the antiderivative which is equal to the function before differentiation. this version of calculus is invertable and fractional calculus derived from these generalized functions could satisfy the index rule.

### we need a change of prespective ###
now we have some idea of why fractional calculus normaly can not satisfy the index rule and have some idea of how to get around it. now lets consider the multiple definitions of fractional calculus. is there any reason why fractional calculus needs multiple definitions, where do the definitions come from? first I looked at the derivation of various fractional derivatis and fractional integrals, but there are a wide nuber of aproches to deriiving fractional calculus all using diferent methods to define the operators. From doing this it demonstates that there are multiple definitions of fractional derivaties and integrals but it did not help me understand why that must be the case. so maby there is a bettery way to approche this problem that make it more clear. however, how do you find such a convienient change of prespective? I did not know that either. So i tinkered with fractional calculus untill i found anything that seamed helpfull, and just kept interating on that. in the end I did find a prospective from which to view fractional calculus that I find simplifies some aspects of it, and provides an answer to why there are multiple definitions.


when trying to see why the derivative is not invertable it was usefull to think of functions in terms of their taylor series as being represented by the collection of coefficent in the taylor series. I have found that that representtation is usefull in this case aswell. now that we are considering fractional derivatives inorder to maintain the view of functions as taylor series, I will assume that we only consider functions which are complex analytic and for which their fractional derivatives are all complex analytic aswell. so given some sutable function $f(z)$ what is its fractional derivative $\frac{d^\alpha}{dz^\alpha} f(z)$ in this series representation. taking $\alpha$ as a variable the series representation as a function of $\alpha$ is $(a_0(\alpha), a_1(\alpha), a_2(\alpha), ..., a_k(\alpha), ...)$, where if $\alpha=0$ it repuduce the function $f(z)$, so $a_k(0) = a_k$. fractional derivative by definition must reproduce repeated differentiation when the index is a positive integer, so given a positive integer $m$ then the functions $a_k(\alpha)$ must satisfy the equaiton $a_k(m) = a_{k + m}$. so in this view a fractional derivative is an operator which takes the series representation of a function and produces a sequence of functions that must be compatible with the original sequence and when evaluated for a paticular value of $\alpha$ it can be interpreted as the sereis reprsentation of $\frac{d^\alpha}{dz^\alpha} f(z)$.

### alternative view of fractional calculus ###
now given this representation of fractional calculus, let us also assume that this fractional derivative satisfies the index rule $\frac{d^\alpha}{dz^\alpha}\frac{d^\beta}{dz^\beta} = \frac{d^{\alpha + \beta}}{dz^{\alpha + \beta}}$ for any $\alpha$ and $\beta$. however we have already see that this is not posible generaly for normal derivative, so we have to also assume that the derivative is invertable (either by restricting to a subset of analytic functions like the set $\mathbb{S}$, or by using generalized functions as mentioned befor). now given these assumtions all of the functions $a_k(\alpha)$ in the sereies representation of a fractional derivative are nessisaraly defined interms of each other, that is due to the index rule $\frac{d^m}{dx^m}\frac{d^\alpha}{dx^\alpha} f(z) = \frac{d^{m + \alpha}}{dx^{m + \alpha}} f(z)$, where $m$ is a positive integer. so the functions $a_k(\alpha)$ must then satisfy the equation $a_{k + m}(\alpha) = a_k(\alpha + m)$, then letting $k = 0$ we get, $a_m(\alpha) = a_0(\alpha + m)$. this means that if a fractional derivative satisfies the index rule the sereis representation of the fractional derivative $\frac{d^\alpha}{dz^\alpha} f(z)$ is entirely defined by $a_0(\alpha)$ and all of the other functions in the sequence are shifted copies of that function.

thinking of this visualy, if we plott the coefficent in the series representation of $f(z)$ vs their index $k$, as the sequence of points $(k, a_k)$ this produces a scatter plot that defines the function if it is complex analytic. considering the series representation of $\frac{d^\alpha}{dz^\alpha}f(z)$, it is defined by $a_0(\alpha)$ and we found prevously that $a_k(m) = a_{k+m}$ so letting $k=0$ then $a_0(m) = a_m$, where $m$ is a positive integer. so the function $a_0(\alpha)$ if plotted on the same graph as the terms $a_k$ must pass through all of the points $(k, a_0(k))$ which coinsides with the points of the sactter plot. So the function which defines $\frac{d^\alpha}{dz^\alpha} f(z)$ is an interpolation between the points $(k, a_k)$. conversly any procedure that given one such scatter plot defines a interplolation between the points $(k, a_k)$ can be viewed as defining a fractional derivative which satisfies the index rule.

### infinite number of fractional derivatives ###
with the connection between fractional differentiation and interpolation it is clear that because there are an infinite number of interpolaiton of any set of coeffidcients, then likewise ther are an infinie number of fractional derivatives of any sutable function wich all satisfy the conditions given previously for fractional derivative with the addition of the index rule. so the is not just that there are multiple definitions of fractional differentiation, there infact must be an infinite number of fractional derivatives, which are all incompatible with each other.


now like constraining to a subset of functions to force the derivative to be invertable, one way to select a unique fractional derivative would be to apply some natural constraint such for any sutible taylor series ther is only one interpolation that satisfies the constraint. this would inturn define a fractional derivative operator, alternativley like when tring to make ther derivative invertable it may be posible to generalize functions such that all of these fractional derivative represent the same underling operation.
