---
layout: post
title: "Fractional Calculus and Taylor Series"
tags: [Math, Taylor-series, Calculus, Fractional-Calculus]
math: true
---

## intro ##
fractional calculus is the attempt to solve equations of the form $\sqrt{\frac{d}{dx}} f(x)$ that is what operator when applied twice is equal to the derivative, and other probems in a simular vane. thinking along those lines we might think about what a fractional derivative actualy is. by its definition it is somthin wich applied multiple times can reprouduce differentiation and anaogusly integration but is there any intution for how it actualy behaves. so the derivation in repeated differentiationof a function produces the slope it takes a graph and iproduse the sope of the graph and curvatue etcetera, and so you might consieve of somthing inbetwean the slope and the curvatue of a graph. that does not imediatly lead to obserdities. in the analogus case of intergration. repeated integration can be thought of finding lengths, areas, volumes. the idea of fractional integrathoin might be thought of finding the size of fractional dimensional cubes. which leads to obvoius obsurdetuies, but ignoring graphical reasoning it seams reasonable that it might exist. just how reapaeated multiplication can be can be extended to exponentiaon, maby repeated differentiation can be exstended to fractional calculus. but the direct intuition for what integration and differentiation does not extend to fractional calculus.

### the problem ###
so taking the analogy between repeated differentiation and repeated multiplication and how that might extend to fractional calculus. there is some properties that it seams to be natural for fractional calculus to satisfy. for example is is natual to assume that $\frac{d^\alpha}{dx^\alpha}\frac{d^\beta}{dx^\beta} = \frac{d^{\alpha + \beta}}{dx^{\alpha + \beta}}$ that makes scens both interms of the loose analogy and interms of the calculus property for repeated differentiation that $\frac{d^n}{dx^n}\frac{d^m}{dx^m} = \frac{d^{n + m}}{dx^{n + m}}$. so it might be natural to asume the analoge aplies to fractional calcculus. however that is not the case. For example the Riemann Luivile fractional derivative is $\color{white}a_{\color{black}a} \color{black} I_{x}^\alpha f(x) = \frac{1}{\Gamma(\alpha)} \int_a^x (x - \tau)^{\alpha - 1} f(\tau) d\tau$. using this fractional derivative $\color{white}a_{\color{black}a} \color{black} I_{x}^{1/2} (\frac{d}{dx} 1)  \neq \frac{d}{dx} (\color{white}a_{\color{black}a} \color{black} I_{x}^\alpha 1)$. and thats not the only odd thing. RLFD one of the more common deffinitions becaus there is infact multiple incompatible definitions of fractional differentiation and integration. so ont eh one hand fractional calculus has properties has very close to neat and simple rules but not quite, it is not even uniquly defined. so my preconseptions of how fractional calculus should be have if it wore for it to be suple but it just does not work. so short of beaing able to modify those propertiys lets t attempt to atleast understand where these propertys come from.

### what is a fractional derivative ###
before jumping I should be clear about wheat i mean by fractional differentiation in the first place. for the perposus here by fractional differentiation, i mean a operator that actions functions and has a variable call the index such that for positive values of the index it reproduce repeaded differentiation. and that like the derivative and integral operators is a linear operator.

### understanding semigroup ###
baced on just ideas of what would be nice about fractional differentiation, that the combination of multiple derivative would be equal to one operator with the index equal to the sume of the others indices. but that is not the case, the comutator of the derivative and semiderivative when acting on a constant function is non-zero. this results in the semigroup property. where does this come from. it is actualy inherited from differential calculus itself. note that often the derivative and integral are refered to as inverses of each other but generaly differentiation and integration does not commute, going one way removes a constant value. so if you consive of derivative and integrals as part of the same operator with an index. the combined operator can combine derivatives with derivatives and integrals with integrals, but not both. this leads to a semigroup like property for this operator. so then a fractional version of this operator must reproduce the original version for integer values. so the fractional version cannot satisfy the index rule and at best can have a semigroup, due to the properties of the derivative.

### invertable by restriction ###
however this leads to an obvious workaround, what if we restriced the domain of functions that we consider for calculsu. such that differentiation and intergration was invertable. if we considered functions of the form $f(x) = P(x)e^x$ where $P(x)$ is a finite order polynomial, lets call the set of all functions of that form $\mathbb{S}$. so consider the collection of $(\mathbb{S}, \int_{-\infinity}^x)f(t)dt, \frac{d}{dx}$, the only antiderivative of a function in $\mathbb{S}$ which is also in the same set is given by the integral listed, and that integral and derivate when restricted to functions in $\mathbb{S}$ are true inverses of each other. so the operator $J^n$ that reproduces repeated integration and differentiation as listed abouve. then this operator when acting on functions in $\mathbb{S}$ forms a group and statisfies the index rule $J^nJ^m f(x) = J^{n+m} f(x)$ for all $n, m \in \mathbb{Z}$. so then it is posible but at this point not garentied that a fractional version of this operator could satisfy the index rule.

### derivative: taylor prespective ###
so restricting the domain of functions is one way to make integration invertable. alternativly we can consider why differentiation is not invertable in the first place. this can be seen from the fundemental theorem of calculus, but a more direct way is to see the action of the derivative on a taylor series. given the nice connection between complex analytic functions and taylor series. lets only consider complex analytic functions so in the domain of the function the taylor series at any point converges and for some nonzero radius and can always be extended uniquely to the full function by analytic continuation. considering an analytic function, looking at the coefficents of its taylor series, the taylor series of the derivative of said functions is equivelent less the first element of the series. so representing the function as mearly a sequence of complex values equivelent to the coefficeints of the taylor series, then the derivative of the function is equal to just removeing the first element of this list. so then taking the nth derivative is likewise equivelent to removieng the first n terms of the sequence. so clearly differentiation is not invertable since there does not exist a function that given one of these sequences can recover the first term of the sequence befor differentiation, that is unless the domain of functions is restricted such that the coefficient would be implied. so differentiation is not invertable due to this loss of information.

### invertable calculus by generalized functions ###
so with this in mind if we wanted to make calculus invertable with out gratly restricting the domain of functions, we could instead broaden the consept of functions along with the associated derivative operator such that every time we differentiate a function the leading term of the taylor series get packadged along with the new function, then the an inverse operator to the derivative nessisaraly exists. the inverse would unpack the most reasent peace of extra information and put it as the first entry of the taylor series followed by the existing ones, this corisponds to precicly the antiderivative which is equal to the function before differentiation. fractional calculus derived from these generalized functions could satisfy the index rule and be less limited in scope.
 
### we need a change of prospective ###
now we have some idea of where the semigroup property comes from and have some idea of how to get around it with out destryoing fractional calculus. now lets consider the multiple definitions of fractional calculus. is there any reason why fractional calculus needs multiple definitions, wher do the definitions come from. but it was not clear what the oriding of the difernt definitions is so maby we need a difernt prespective to make it clear. however how do you find such a convientent change of prespective. that is probably an even harder problem, so instead i just tinkered with fractional calculus untill i came across somthing that appeared usefull. in the end that did lead to an usefull prespective for simplifying some aspects of fractional calculus.

### Fractional calculus and analytic functions ###
in a way simular to how with when trying to see why the derivative is not invertable it was usefull to think of functions as taylor series, as aposed to more useual representations. I have found that that representtation is usefull in this case aswell. now that we are considering fractional derivatives inorder to maintain the view of functions as taylor series, I will assume that we only consider functions which are analytic and for which their fractional derivatives are all analytic aswell. so given some sutable analytic function $f(x)$ what is its fractional derivative $\frac{d^\alpha}{dx^\alpha} f(x)$ in this taylor series representation. we have already assumed that the result is analytic and $\alpha$ is arbitrary so rather thatn a sequence of numers $a_n$ it must be a sequence of functions $a_n(\alpha)$ such that for $\alpha = 0$ it is equal to the original sequence and such that when $\alpha$ is a positive integer $m$ the sequence reproduces the mth derivative $a_{n - m}$ droping the first m terms.

### the change in prospective ###
now we are ready to chane our prospective in a usefull way. if we take this fractional derivative that and functions such that the function and is fractional derivative is always analytic, if we then inaddition assume that the index rule applies then all of the functions $a_n(\alpha)$ are nessisaraly defined interms of each other. that is due to the index rule $\frac{d^m}{dx^m}\frac{d^\alpha}{dx^\alpha}f(x) = \frac{d^{m + \alpha}}{dx^{m + \alpha}} f(x)$ so $a_{n + m}(\alpha) = a_n(\alpha + m)$, letting $n = 0$ we get, $a_m(\alpha) = a_0(\alpha + m)$. that is to say that all of the functions defining the terms of the taylor series are infact shifted copies of the same function given the index rule is true. so given a scatter plot of the coefficients $a_n$ vs the indices $n$ then any fractional derivative that satisfies the index rule defines an interpolation between the points on the plot, and conversly any procedure that given one such scatter plot defines a interplolation can be viewed as defining a fractional derivative wich satisfies the index rule.

### infinite number of fractional derivatives ###
with the connection between fractional differentiation and interpolation it is clear that because there are an infinite number of interpolaiton of any set of coeffidcients, then likewise ther are an infinie number of fractional derivatives of any sutable function wich all satisfy the conditions given previously for fractional derivative with the addition of the index rule. so the is not just multiple fractional definitions of fractional differentiation, there must an infinite number of fractional derivatives, wich are all valid and incompatible with eachother.

### adding a constraint ###
now like constraining the domain of calculus to force it to be invertable, one wayto select a unique fractional derivative would be to apply some natural constraint such for any sutible taylor series ther is only one interpolation that satisfies the constraint. this would inturn define a fractional derivative operator, alternativley like when tring to make ther derivative invertable it may be posible to generalize functions such that all of these fractional derivative represent the same underling operation.


